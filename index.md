---
layout: page
description: >
  Jin WANG's homepage.
hide_description: true
redirect_from:
  - /homepage/
no_link_title: false 
no_excerpt: false 
hide_image: true
---

# About

Hi! My name is **Jin Wang**. I am a third-year Ph. D. student in Bioengineering and Robotics at [Italian Institute of Technology](https://www.iit.it/) (IIT), advised by [Nikos Tsagarakis](https://hhcm.iit.it/our-staff-details/-/people/nikos-tsagarakis) as part of the Humanoids and Human Centered Mechatronics ([HHCM](https://hhcm.iit.it/home)) lab. I am currently a visiting researcher at the [Oxford Robotics Institute](https://ori.ox.ac.uk/), [DRS-C lab](https://ori.ox.ac.uk/labs/drs-control/), working with [Ioannis Havoutis](https://ihavoutis.github.io/). My research interests lie in **humanoids**, **embodied AI** and **robot learning**. More specifically, I‚Äôm focusing on autonomous robotic loco-manipulation, integrating foundation models into robot tasks and improving autonomy through learning.

I am deeply committed to cross-disciplinary teamwork, leveraging engineering mindsets to address real-world challenges. And I‚Äôm passionate about novel robotic design and exploring the intelligence and potential value of robots.

Previously, I was a Master student in Robotics at [LIRMM CNRS](https://www.lirmm.fr/teams-en/IDH-en/), France. I received my B.A. in Robotics Union Academy Guangdong-HongKong at GDUT.


## News üì∞
- [Jul, 2025] I'm starting a new position as Visiting Researcher at [Oxford Robotics Institute](https://ori.ox.ac.uk/), University of Oxford.üßëüèº‚Äçüéì
- [May, 2025] Our IROS 2025 Workshop proposal [Embodied AI and Robotics for Future Scientific Discovery](https://airobot4sci.github.io/) has been accepted!üéâ
- [Nov, 2024] One paper accepted by [WCBM Workshop](https://wcbm-workshop.github.io/) at CoRL 2024. üìÉ
- [Oct, 2024] Invited talks by ZHIDX  [Frontiers of Embodied AI Lecture](https://course.zhidx.com/c/MGZjNWEzOWJjZDcxODhlNTg2OTM=). üí¨
- [Sep, 2024] [HYPERmotion](https://hy-motion.github.io/) is accepted by CoRL 2024. üéâ
- [Aug, 2024] One paper accepted by ICRA@40. üìÉ
- [Jul, 2024] One paper accepted by IROS 2024 for an oral presentation. ‚ú®
- [Jul, 2023] Summer school 'Learning-based MPC' at ETHz üö°

# Research
## Featured Publications


<div style="display: flex; align-items: flex-start; margin-bottom: 20px;">

  <!-- aurora -->
  <div style="flex: 1; padding-right: 20px;">
    <a href="https://robo-intention.github.io/">
      <video playsinline autoplay loop muted src="assets/img/research/aurora.png" poster="assets/img/research/aurora.png" alt="sym" width="100%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;"></video>
    </a>
  </div>

  <!-- Âè≥‰æßÔºöËÆ∫Êñá‰ø°ÊÅØ -->
  <div style="flex: 1;">
    <p><a href="https://robo-intention.github.io/" id="AURORA">
      <strong>Thinking-with-Memory: Empowering Robots with Transferable Embodied Cognition</strong></a><br>
      <strong>Jin Wang</strong>, Nikos Tsagarakis<br>
      <em>Under Review</em><br>
    </p>
  </div>
</div>

<div style="display: flex; align-items: flex-start; margin-bottom: 20px;">

  <!-- Intention -->
  <div style="flex: 1; padding-right: 20px;">
    <a href="https://robo-intention.github.io/">
      <video playsinline autoplay loop muted src="assets/video/intention_web.mp4" poster="assets/img/research/intention_web.gif" alt="sym" width="100%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;"></video>
    </a>
  </div>

  <!-- Âè≥‰æßÔºöËÆ∫Êñá‰ø°ÊÅØ -->
  <div style="flex: 1;">
    <p><a href="https://robo-intention.github.io/" id="INTENTION">
      <strong>INTENTION: Inferring Tendencies of Humanoid Robot Motion Through Interactive Intuition and Grounded VLM</strong></a><br>
      <strong>Jin Wang</strong>, Weijie Wang, Boyuan Deng, Heng Zhang, Rui Dai, Nikos Tsagarakis<br>
      <em>International Conference on Humanoid Robots (<strong>HUMANOIDS 2025</strong>)</em>
      <span style="color:red; font-weight:bold;">Oral</span><br>
    </p>

    <p>
      <a href="https://robo-intention.github.io/">webpage</a> |
      <a href="https://robo-intention.github.io/">pdf</a> |
      <a href="https://robo-intention.github.io/">arXiv</a> |
      <a href="https://robo-intention.github.io/">code</a> |
      <a href="https://www.youtube.com/watch?v=kCupbUgBtXQ">video</a>
    </p>

  </div>
</div>

<div style="display: flex; align-items: flex-start; margin-bottom: 20px;">

  <!-- RoboNurse -->
  <div style="flex: 1; padding-right: 20px;">
    <a href="https://robonurse-vla.github.io/">
      <video playsinline autoplay loop muted src="assets/video/robonurse.mp4" poster="assets/img/research/robonurse.gif" alt="sym" width="100%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;"></video>
    </a>
  </div>

  <!-- Âè≥‰æßÔºöËÆ∫Êñá‰ø°ÊÅØ -->
  <div style="flex: 1;">
    <p><a href="https://robonurse-vla.github.io/" id="ROBONURSE">
      <strong>RoboNurse-VLA: Robotic Scrub Nurse System based on Vision-Language-Action</strong></a><br>
      Shunlei Li, <strong>Jin Wang</strong>, Rui Dai, Wanyu Ma, Wing Yin Ng, Yingbai Hu, Zheng Li<br>
      <em>International Conference on Intelligent Robots and Systems (<strong>IROS 2025</strong>)</em>
      <span style="color:red; font-weight:bold;">Oral</span><br>
    </p>

    <p>
      <a href="https://robonurse-vla.github.io/">webpage</a> |
      <a href="https://arxiv.org/pdf/2409.19590">pdf</a> |
      <a href="https://arxiv.org/abs/2409.19590">arXiv</a> |
      <a href="https://robonurse-vla.github.io/">code</a> |
      <a href="https://www.youtube.com/watch?v=JT10qDkUb38">video</a>
    </p>

  </div>
</div>

<div style="display: flex; align-items: flex-start; margin-bottom: 20px;">

  <!-- Recovery -->
  <div style="flex: 1; padding-right: 20px;">
    <a href="https://boyuandeng.github.io/L2R-WheelLegCoordination/">
      <video playsinline autoplay loop muted src="assets/video/recovery.png" poster="assets/img/research/recovery.png" alt="sym" width="100%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;"></video>
    </a>
  </div>

  <!-- Âè≥‰æßÔºöËÆ∫Êñá‰ø°ÊÅØ -->
  <div style="flex: 1;">
    <p><a href="https://boyuandeng.github.io/L2R-WheelLegCoordination/" id="RECOVER">
      <strong>Learning to Recover: Dynamic Reward Shaping with Wheel-Leg Coordination for Fallen Robots</strong></a><br>
      Boyuan Deng, Luca Rossini, <strong>Jin Wang</strong>, Weijie Wang, Nikos Tsagarakis<br>
      <em><strong>arXiv</strong></em><br>
    </p>

    <p>
      <a href="https://boyuandeng.github.io/L2R-WheelLegCoordination/">webpage</a> |
      <a href="https://arxiv.org/pdf/2506.05516">pdf</a> |
      <a href="https://arxiv.org/abs/2506.05516">arXiv</a> |
      <a href="https://boyuandeng.github.io/L2R-WheelLegCoordination/">code</a> |
      <a href="https://www.youtube.com/watch?v=78Ur4Cb2AS4&t=1s">video</a>
    </p>

  </div>
</div>


<div style="display: flex; align-items: flex-start; margin-bottom: 20px;">

  <!-- Hymotion -->
  <div style="flex: 1; padding-right: 20px;">
    <a href="https://hy-motion.github.io/">
      <video playsinline autoplay loop muted src="assets/video/hymotion.mp4" poster="assets/img/research/hymotion.gif" alt="sym" width="100%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;"></video>
    </a>
  </div>

  <!-- Âè≥‰æßÔºöËÆ∫Êñá‰ø°ÊÅØ -->
  <div style="flex: 1;">
    <p><a href="https://hy-motion.github.io/" id="HYPERMOTION">
      <strong>HYPERmotion: Learning Hybrid Behavior Planning for Autonomous Loco-manipulation</strong></a><br>
      <strong>Jin Wang</strong>, Rui Dai, Weijie Wang, Luca Rossini, Francesco Ruscelli, Nikos Tsagarakis<br>
      <em>8th Conference on Robot Learning (<strong>CoRL 2024</strong>)</em><br>
    </p>

    <p>
      <a href="https://hy-motion.github.io/">webpage</a> |
      <a href="https://openreview.net/forum?id=ma7McOiCZY">pdf</a> |
      <a href="https://arxiv.org/abs/2406.14655v1">arXiv</a> |
      <a href="https://hy-motion.github.io/">code</a> |
      <a href="https://www.youtube.com/embed/P-Y_fzpjlhY?si=9S3ZT4HDTwwdufXY">video</a>
    </p>

  </div>
</div>


<div style="display: flex; align-items: flex-start; margin-bottom: 20px;">

  <!-- IROS24 -->
  <div style="flex: 1; padding-right: 20px;">
    <a href="https://arxiv.org/abs/2408.08282">
      <video playsinline autoplay loop muted src="assets/video/iros2024.mp4" poster="assets/img/research/iros2024.gif" alt="sym" width="100%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;"></video>
    </a>
  </div>

  <!-- Âè≥‰æßÔºöËÆ∫Êñá‰ø°ÊÅØ -->
  <div style="flex: 1;">
    <p><a href="https://arxiv.org/abs/2408.08282" id="IROS24">
      <strong>Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model</strong></a><br>
      <strong>Jin Wang</strong>, Arturo Laurenzi, Nikos Tsagarakis<br>
      <em>International Conference on Intelligent Robots and Systems (<strong>IROS 2024</strong>)</em>
      <span style="color:red; font-weight:bold;">Oral</span><br>
    </p>

    <p>
      <a href="https://arxiv.org/abs/2408.08282">pdf</a> |
      <a href="https://arxiv.org/abs/2408.08282">arXiv</a> |
      <a href="https://arxiv.org/abs/2408.08282">code</a> |
      <a href="https://www.youtube.com/watch?v=mmnaxthEX34">video</a>
    </p>

  </div>
</div>

<div style="display: flex; align-items: flex-start; margin-bottom: 20px;">

  <!-- Â∑¶‰æßÔºöËÆ∫Êñá GIF Âä®Âõæ -->
  <div style="flex: 1; padding-right: 20px;">
    <a href="https://arxiv.org/abs/2409.01326">
      <video playsinline autoplay loop muted src="assets/img/research/ICRA@40.png" poster="assets/img/research/ICRA@40.png" alt="sym" width="100%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;"></video>
    </a>
  </div>

  <!-- Âè≥‰æßÔºöËÆ∫Êñá‰ø°ÊÅØ -->
  <div style="flex: 1;">
    <p><a href="https://arxiv.org/abs/2409.01326" id="HYPERMOTION">
      <strong>Grounding Language Models in Autonomous Loco-manipulation Tasks</strong></a><br>
      <strong>Jin Wang</strong>, Nikos Tsagarakis<br>
      <em>International Conference on Robotics and Automation<strong>ICRA@40</strong></em><br>
    </p>

    <p>
      <a href="https://arxiv.org/abs/2409.01326">pdf</a> |
      <a href="https://arxiv.org/abs/2409.01326">arXiv</a> |
    </p>

  </div>
</div>


# Project

TBD